Nom du pdf : Mikolov 2013 Distributed representations of words and phrases and their compositionality
Titre :  Distributed representations of words and phrases and their compositionality
Resumé : The recently introduced continuous Skip-gram model is an efficient method forlearning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we presentseveral extensions that improve both the quality of the vectors and the trainingspeed. By subsampling of the frequent words we obtain significant speedup andalso learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling.An inherent limitation of word representations is their indifference to word orderand their inability to represent idiomatic phrases. For example, the meanings of“Canada” and “Air” cannot be easily combined to obtain “Air Canada”. Motivatedby this example, we present a simple method for finding phrases in text, and showthat learning good vector representations for millions of phrases is possible.